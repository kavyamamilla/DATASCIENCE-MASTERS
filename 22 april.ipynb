{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YehCPMVW3_8S"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the KNN classifier\n",
        "k = 3  # Number of neighbors\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, we first load the load_iris dataset, split it into training and testing sets, and then initialize a KNN classifier with a specified number of neighbors (k). We fit the classifier on the training data and use it to predict the labels for the test data. Finally, we calculate and print the accuracy of the classifier using the predicted and true labels."
      ],
      "metadata": {
        "id": "tC85ucRn4If9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the dataset\n",
        "boston = load_boston()\n",
        "X = boston.data\n",
        "y = boston.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the KNN regressor\n",
        "k = 5  # Number of neighbors\n",
        "knn_regressor = KNeighborsRegressor(n_neighbors=k)\n",
        "\n",
        "# Fit the regressor on the training data\n",
        "knn_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = knn_regressor.predict(X_test)\n",
        "\n",
        "# Calculate and print the mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ],
      "metadata": {
        "id": "rHw9QnKG4Brn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, we load the load_boston dataset, split it into training and testing sets, and then initialize a KNN regressor with a specified number of neighbors (k). We fit the regressor on the training data and use it to predict the target values for the test data. Finally, we calculate and print the mean squared error to assess the performance of the regressor"
      ],
      "metadata": {
        "id": "CMhv0uHS4UpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets (optional for cross-validation)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a list of potential K values to test\n",
        "k_values = list(range(1, 31))  # Range of K values to consider\n",
        "\n",
        "# Initialize an empty list to store cross-validation scores for each K value\n",
        "cross_val_scores = []\n",
        "\n",
        "# Perform cross-validation for each K value\n",
        "for k in k_values:\n",
        "    knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
        "    scores = cross_val_score(knn_classifier, X_train, y_train, cv=5)  # 5-fold cross-validation\n",
        "    cross_val_scores.append(scores.mean())\n",
        "\n",
        "# Find the optimal K value with the highest cross-validation score\n",
        "optimal_k = k_values[cross_val_scores.index(max(cross_val_scores))]\n",
        "\n",
        "print(\"Optimal K value:\", optimal_k)\n"
      ],
      "metadata": {
        "id": "6CbQf3Eb4X8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, we perform 5-fold cross-validation for each potential K value using the cross_val_score function. We calculate the mean of the cross-validation scores for each K value and determine the optimal K value as the one with the highest cross-validation score."
      ],
      "metadata": {
        "id": "U0AeOTxw4fsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the dataset\n",
        "boston = load_boston()\n",
        "X = boston.data\n",
        "y = boston.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the StandardScaler to scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize the KNN regressor\n",
        "k = 5  # Number of neighbors\n",
        "knn_regressor = KNeighborsRegressor(n_neighbors=k)\n",
        "\n",
        "# Fit the regressor on the scaled training data\n",
        "knn_regressor.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the scaled test data\n",
        "y_pred = knn_regressor.predict(X_test_scaled)\n",
        "\n",
        "# Calculate and print the mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ],
      "metadata": {
        "id": "66brmBQX4kCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, we load the load_boston dataset, split it into training and testing sets, and then use StandardScaler to scale the features. Feature scaling is important for KNN as it ensures that all features are on similar scales, which can improve the performance of the algorithm. We then initialize a KNN regressor, fit it on the scaled training data, and predict the target values for the scaled test data. Finally, we calculate and print the mean squared error to assess the performance of the regressor."
      ],
      "metadata": {
        "id": "dnHH8u8s4n0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the KNN classifier with weighted voting\n",
        "k = 3  # Number of neighbors\n",
        "weights = 'distance'  # 'distance' for weighted voting, 'uniform' for equal voting\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=k, weights=weights)\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = (y_pred == y_test).sum() / len(y_test)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "J_4lNW0X4qyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, we load the load_iris dataset, split it into training and testing sets, and then initialize a KNN classifier with weighted voting. We use the weights parameter to specify whether to use 'distance' for weighted voting or 'uniform' for equal voting. We fit the classifier on the training data and use it to predict the labels for the test data. Finally, we calculate and print the accuracy of the classifier using the predicted and true labels."
      ],
      "metadata": {
        "id": "yuU2Sx924vqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "def knn_classifier_with_standardization(X_train, X_test, y_train, y_test, k):\n",
        "    # Initialize the StandardScaler to scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Initialize the KNN classifier\n",
        "    knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "    # Fit the classifier on the scaled training data\n",
        "    knn_classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Make predictions on the scaled test data\n",
        "    y_pred = knn_classifier.predict(X_test_scaled)\n",
        "\n",
        "    # Calculate and return the accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    return accuracy\n",
        "\n",
        "# Call the function with a specified number of neighbors (k)\n",
        "k = 3\n",
        "accuracy = knn_classifier_with_standardization(X_train, X_test, y_train, y_test, k)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "X6zrO1Yy4ypc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, the knn_classifier_with_standardization function takes the training and test data, as well as the number of neighbors (k) as inputs. Inside the function, the features are standardized using StandardScaler, and then a KNN classifier is initialized and trained on the scaled training data. The function returns the accuracy of the classifier on the test data."
      ],
      "metadata": {
        "id": "SJFUxeb_42yG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def euclidean_distance(point1, point2):\n",
        "    \"\"\"\n",
        "    Calculate the Euclidean distance between two points.\n",
        "\n",
        "    Parameters:\n",
        "        point1 (array-like): The coordinates of the first point.\n",
        "        point2 (array-like): The coordinates of the second point.\n",
        "\n",
        "    Returns:\n",
        "        float: The Euclidean distance between the two points.\n",
        "    \"\"\"\n",
        "    point1 = np.array(point1)\n",
        "    point2 = np.array(point2)\n",
        "    distance = np.sqrt(np.sum((point1 - point2)**2))\n",
        "    return distance\n",
        "\n",
        "# Example usage\n",
        "point1 = [1, 2, 3]\n",
        "point2 = [4, 5, 6]\n",
        "distance = euclidean_distance(point1, point2)\n",
        "print(\"Euclidean Distance:\", distance)\n"
      ],
      "metadata": {
        "id": "Wn_ochVm45ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, the euclidean_distance function takes two array-like inputs (point1 and point2) representing the coordinates of two points. It uses NumPy to perform element-wise subtraction, squaring, and summing of the differences, and then takes the square root to calculate the Euclidean distance."
      ],
      "metadata": {
        "id": "_XLwtdM74-cC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def manhattan_distance(point1, point2):\n",
        "    \"\"\"\n",
        "    Calculate the Manhattan distance between two points.\n",
        "\n",
        "    Parameters:\n",
        "        point1 (array-like): The coordinates of the first point.\n",
        "        point2 (array-like): The coordinates of the second point.\n",
        "\n",
        "    Returns:\n",
        "        float: The Manhattan distance between the two points.\n",
        "    \"\"\"\n",
        "    point1 = np.array(point1)\n",
        "    point2 = np.array(point2)\n",
        "    distance = np.sum(np.abs(point1 - point2))\n",
        "    return distance\n",
        "\n",
        "# Example usage\n",
        "point1 = [1, 2, 3]\n",
        "point2 = [4, 5, 6]\n",
        "distance = manhattan_distance(point1, point2)\n",
        "print(\"Manhattan Distance:\", distance)\n"
      ],
      "metadata": {
        "id": "kIhglkXI5BE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, the manhattan_distance function takes two array-like inputs (point1 and point2) representing the coordinates of two points. It uses NumPy to calculate the absolute differences between corresponding coordinates and then sums up those absolute differences to calculate the Manhattan distance."
      ],
      "metadata": {
        "id": "Kz_I3zMR5EOZ"
      }
    }
  ]
}